{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astra Guardian: Model Testing and Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the full functionality of the Astra Guardian system. It loads the trained models and artifacts to classify network traffic into one of three categories:\\n",
    "\\n",
    "1. **Known Application**: Traffic that is identified as a known application (e.g., Google, YouTube).\\n",
    "2. **Unknown Anomaly**: Traffic that does not conform to the patterns of known, normal applications.\\n",
    "3. **Masquerading Threat**: Traffic that is classified as a known application but exhibits anomalous behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Artifacts and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\\n",
    "import pandas as pd\\n",
    "import numpy as np\\n",
    "from tensorflow.keras.models import load_model\\n",
    "from sklearn.metrics import accuracy_score, classification_report\\n",
    "import matplotlib.pyplot as plt\\n",
    "import seaborn as sns\\n",
    "\\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved artifacts\\n",
    "autoencoder = load_model('../artifacts/autoencoder.h5')\\n",
    "classifier = joblib.load('../artifacts/classifier.joblib')\\n",
    "scaler = joblib.load('../artifacts/scaler.joblib')\\n",
    "label_encoder = joblib.load('../artifacts/label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data (we'll re-create it for demonstration)\\n",
    "from astra_guardian.preprocessing import clean_and_prepare_data, encode_and_split_data\\n",
    "\\n",
    "df = pd.read_csv('../data/Dataset-Unicauca-Version2-87Atts.csv')\\n",
    "df_clean = clean_and_prepare_data(df)\\n",
    "_, X_test, _, y_test, _, _ = encode_and_split_data(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\\n",
    "accuracy = accuracy_score(y_test, y_pred)\\n",
    "print(f'Classifier Accuracy: {accuracy:.4f}')\\n",
    "print('\\nClassification Report:')\\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Establish Anomaly Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify anomalies, we calculate the reconstruction error for each data point. We'll establish a threshold based on the distribution of these errors for the test set. Any data point with an error above this threshold will be considered an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pred = autoencoder.predict(X_test)\\n",
    "mse = np.mean(np.power(X_test - X_test_pred, 2), axis=1)\\n",
    "\\n",
    "plt.figure(figsize=(10, 6))\\n",
    "sns.histplot(mse, bins=50, kde=True)\\n",
    "plt.title('Reconstruction Error Distribution')\\n",
    "plt.xlabel('Mean Squared Error')\\n",
    "plt.ylabel('Frequency')\\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the anomaly threshold (e.g., 95th percentile)\\n",
    "anomaly_threshold = np.quantile(mse, 0.95)\\n",
    "print(f'Anomaly Threshold (95th percentile): {anomaly_threshold:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identify Masquerading Threats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A masquerading threat is a flow that the classifier confidently identifies as a known application, but the anomaly detector flags as anomalous. We'll find examples of these by looking for high-confidence predictions with high reconstruction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = classifier.predict_proba(X_test)\\n",
    "confidence = np.max(y_pred_proba, axis=1)\\n",
    "\\n",
    "# Find masquerading threats\\n",
    "masquerading_threats = (confidence > 0.9) & (mse > anomaly_threshold)\\n",
    "\\n",
    "print(f'Found {np.sum(masquerading_threats)} potential masquerading threats.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some examples\\n",
    "masquerading_df = pd.DataFrame({'y_true': y_test[masquerading_threats], 'y_pred': y_pred[masquerading_threats], 'confidence': confidence[masquerading_threats], 'mse': mse[masquerading_threats]})\\n",
    "masquerading_df['y_true'] = label_encoder.inverse_transform(masquerading_df['y_true'])\\n",
    "masquerading_df['y_pred'] = label_encoder.inverse_transform(masquerading_df['y_pred'])\\n",
    "\\n",
    "print('Examples of Masquerading Threats:')\\n",
    "masquerading_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
